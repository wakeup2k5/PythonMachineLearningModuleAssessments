{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Breast Cancer Campaign\n",
    "Classify the diagnosis for a patient based on the same features collected from the Wisconsin Breast Cancer dataset.\n",
    "\n",
    "You are required to:\n",
    "- Select the most important features in the Breast Cancer dataset.\n",
    "- Train multiple classifiers on the dataset to predict the diagnosis class.\n",
    "- Achieve an acceptable accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
       "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
       "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
       "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
       "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  diagnosis  \n",
       "0            3.283515        2.652874             2.532475          1  \n",
       "1           -0.487072       -0.023846             0.548144          1  \n",
       "2            1.052926        1.363478             2.037231          1  \n",
       "3            3.402909        1.915897             1.451707          1  \n",
       "4            0.539340        1.371011             1.428493          1  \n",
       "..                ...             ...                  ...        ...  \n",
       "564          0.219060        1.947285             2.320965          1  \n",
       "565         -0.017833        0.693043             1.263669          1  \n",
       "566         -0.038680        0.046588             0.105777          1  \n",
       "567          3.272144        3.296944             2.658866          1  \n",
       "568         -1.150752       -1.114873            -1.261820          0  \n",
       "\n",
       "[569 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_refined.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Choosing only the most important features for training your classifier is one of the most important steps of the machine learning process. This can be done in many ways.\n",
    "\n",
    "One of the simplest approaches is choosing the features with the highest correlation to the target data.\n",
    "\n",
    "The label in this case is the ‘Diagnosed’ column.\n",
    "\n",
    "The Diagnosed column has two distinct values:\n",
    "- M: Malignant Tumor\n",
    "- B: Benign Tumor\n",
    "\n",
    "Calculate the correlation of all the features to their target labels.\n",
    "\n",
    "Choose the most correlated features above a certain limit for training.\n",
    "Output a list of important feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean            0.730029\n",
       "texture_mean           0.415185\n",
       "perimeter_mean         0.742636\n",
       "area_mean              0.708984\n",
       "smoothness_mean        0.358560\n",
       "compactness_mean       0.596534\n",
       "concavity_mean         0.696360\n",
       "concave points_mean    0.776614\n",
       "Name: diagnosis, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = df.corr()[\"diagnosis\"].drop(\"diagnosis\")\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius_mean is above 0 so is considered important\n",
      "texture_mean is above 0 so is considered important\n",
      "perimeter_mean is above 0 so is considered important\n",
      "area_mean is above 0 so is considered important\n",
      "smoothness_mean is above 0 so is considered important\n",
      "compactness_mean is above 0 so is considered important\n",
      "concavity_mean is above 0 so is considered important\n",
      "concave points_mean is above 0 so is considered important\n",
      "['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean']\n"
     ]
    }
   ],
   "source": [
    "# threshold = 0.7\n",
    "threshold = 0 # changed this to 0 to return all features and yield higher accuracy\n",
    "important_features = []\n",
    "for i in range(len(correlations.values)):\n",
    "    if correlations.values[i] > threshold:\n",
    "        print(correlations.index[i],\"is above\", threshold,\"so is considered important\")\n",
    "        important_features.append(correlations.index[i])\n",
    "   \n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data\n",
    "\n",
    "Split your data as follows:\n",
    "- 80% training set\n",
    "- 10% validation set\n",
    "- 10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 57 57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[important_features]\n",
    "y = df[\"diagnosis\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_test), len(X_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifiers\n",
    "\n",
    "Use KNN classifier, random forest classifier, and support vector classifier (SVC) models to train your data.\n",
    "\n",
    "Train your full features dataset and your reduced set features dataset.\n",
    "\n",
    "Get accuracy scores and confusion matrices for both. You need a minimum accuracy score of 94%.\n",
    "\n",
    "Compare the results.\n",
    "\n",
    "Hint: you need to choose the optimal value for k using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier Accuracy = 0.9298245614035088\n",
      "RandomForestClassifier Accuracy = 0.9824561403508771\n",
      "SVC Accuracy = 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNCmodel = KNeighborsClassifier(n_neighbors= 3)\n",
    "kNCmodel.fit(X_train, y_train)\n",
    "y_pred = kNCmodel.predict(X_test)\n",
    "score = kNCmodel.score(X_validate, y_validate)\n",
    "print(\"KNeighborsClassifier Accuracy =\", score)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rFCmodel = RandomForestClassifier(random_state=0, criterion=\"gini\", n_estimators=700)\n",
    "rFCmodel.fit(X_train, y_train)\n",
    "y_pred = rFCmodel.predict(X_test)\n",
    "score = rFCmodel.score(X_validate, y_validate)\n",
    "print(\"RandomForestClassifier Accuracy =\", score)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "sVCmodel = SVC(kernel=\"linear\", gamma=\"auto\", C=1.0)\n",
    "sVCmodel.fit(X_train, y_train)\n",
    "y_pred = sVCmodel.predict(X_test)\n",
    "score = sVCmodel.score(X_validate, y_validate)\n",
    "print(\"SVC Accuracy =\", score)\n",
    "\n",
    "# I adjusted my threshold value for choosing important features in order to compare all features to the important ones\n",
    "# e.g. threshold = 0 for all vs. threshold = 0.7 for what I thought were important ones\n",
    "# I found that RandomForestClassifier using n_estimators around 600 and the entire features set (previously refined in previous miniproject), yielded the best accuracy (98%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcs_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
